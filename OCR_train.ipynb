{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-oQBc-BAWR",
        "colab_type": "code",
        "outputId": "e90583a5-e96b-4650-f1e9-8c0c83cdda58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTtxokEgBjzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip '/content/drive/My Drive/LicensePlates/NEW/data/autoriaNumberplateOcrRu-2019-08-30.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zrsdf3HB6uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKO3BSTCFr5",
        "colab_type": "code",
        "outputId": "b205ff8b-9afe-4811-9c37-ac13efce0fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# !cp -r '/content/drive/My Drive/LicensePlates/NEW/data/autoriaNumberplateOcrRu-2019-08-30' ocr_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot access '/content/drive/My Drive/LicensePlates/NEW/data/autoriaNumberplateOcrRu-2019-08-30/train/img': Input/output error\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDgregz3ORGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mcm\n",
        "import os\n",
        "from tensorflow.python.client import device_lib\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "import pathlib\n",
        "latest_models = {\n",
        "  \"Detector\": {\n",
        "    \"mrcnn\": {\n",
        "      \"h5\": {\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/mrcnn/mask_rcnn_numberplate_1000_2019_10_07.h5\",\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/mrcnn/mask_rcnn_numberplate_1000_2019_10_07.h5\"\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"OptionsDetector\": {\n",
        "    \"simple\": {\n",
        "      \"h5\": {\n",
        "        \"class_region\": [\n",
        "          \"xx_unknown\",\n",
        "          \"eu_ua_2015\",\n",
        "          \"eu_ua_2004\",\n",
        "          \"eu_ua_1995\",\n",
        "          \"eu\",\n",
        "          \"xx_transit\",\n",
        "          \"ru\",\n",
        "          \"kz\",\n",
        "          \"eu-ua-fake-dnr\",\n",
        "          \"eu-ua-fake-lnr\",\n",
        "          \"ge\"\n",
        "        ],\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/options/0.3.x/numberplate_options_2019_10_07.h5\",\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/options/0.3.x/numberplate_options_2019_10_07.h5\"\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"TextDetector\": {\n",
        "    \"eu_ua_2004_2015\": {\n",
        "      \"h5\": {\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/ua/anpr_ocr_ua_17-gpu.h5\",\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/ua/anpr_ocr_ua_17-cpu.h5\"\n",
        "      }\n",
        "    },\n",
        "    \"eu_ua_1995\": {\n",
        "      \"h5\": {\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/ua-1995/anpr_ocr_ua-1995_2-gpu.h5\",\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/ua-1995/anpr_ocr_ua-1995_2-cpu.h5\"\n",
        "      }\n",
        "    },\n",
        "    \"eu\": {\n",
        "      \"h5\": {\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/eu/anpr_ocr_eu_2-cpu.h5\",\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/eu/anpr_ocr_eu_2-gpu.h5\"\n",
        "      }\n",
        "    },\n",
        "    \"ru\": {\n",
        "      \"h5\": {\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/ru/anpr_ocr_ru_6-cpu.h5\",\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/ru/anpr_ocr_ru_6-gpu.h5\"\n",
        "      }\n",
        "    },\n",
        "    \"kz\": {\n",
        "      \"h5\": {\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/kz/anpr_ocr_kz_4-cpu.h5\",\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/kz/anpr_ocr_kz_4-gpu.h5\"\n",
        "      }\n",
        "    },\n",
        "    \"ge\": {\n",
        "      \"h5\": {\n",
        "        \"cpu\": \"https://nomeroff.net.ua/models/ocr/ge/anpr_ocr_ge_3-cpu.h5\",\n",
        "        \"gpu\": \"https://nomeroff.net.ua/models/ocr/ge/anpr_ocr_ge_3-gpu.h5\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "device_mode = 'gpu'\n",
        "def download_latest_model(detector, model_name, ext=\"h5\", mode = device_mode):\n",
        "    if mode != \"cpu\" and mode != \"gpu\":\n",
        "        mode = device_mode\n",
        "    info = latest_models[detector][model_name][ext]\n",
        "    info[\"path\"] = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"./models\", detector, model_name, os.path.basename(info[mode]))\n",
        "\n",
        "    p = pathlib.Path(os.path.dirname(info[\"path\"]))\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(info[\"path\"]):\n",
        "        #print(\"downloading model {} to {} ...\".format(info[mode], info[\"path\"]))\n",
        "        download_url(info[mode], info['path'])\n",
        "\n",
        "    return info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDcFrAqHPAdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "\n",
        "ia.seed(1)\n",
        "\n",
        "def aug(imgs):\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "    seq = iaa.Sequential(\n",
        "        [\n",
        "             sometimes(iaa.Crop(percent=(0, 0.01))),\n",
        "             iaa.Affine(\n",
        "                 scale={\"x\": (0.995, 1.01), \"y\": (0.995, 1.01)},\n",
        "                 translate_percent={\"x\": (-0.01, 0.01), \"y\": (-0.01, 0.01)},\n",
        "                 rotate=(-3, 3),\n",
        "                 shear=(-3, 3),\n",
        "                 #cval=(0, 255)\n",
        "             ),\n",
        "              iaa.SomeOf((0, 5),\n",
        "              [\n",
        "                      sometimes(iaa.OneOf([\n",
        "                              iaa.OneOf([\n",
        "                                  iaa.GaussianBlur((1, 1.2)),\n",
        "                                  iaa.AverageBlur(k=(1, 3)),\n",
        "                                  iaa.MedianBlur(k=(1, 3))\n",
        "                              ]),\n",
        "                              iaa.ContrastNormalization((0.5, 1.5), per_channel=0.5),\n",
        "                              iaa.Grayscale(alpha=(0.0, 1.0)),\n",
        "                              iaa.OneOf([\n",
        "                                  iaa.EdgeDetect(alpha=(0, 0.7)),\n",
        "                                  iaa.DirectedEdgeDetect(\n",
        "                                      alpha=(0, 0.7), direction=(0.0, 1.0)\n",
        "                                  ),\n",
        "                              ]),\n",
        "                      ])),\n",
        "                      sometimes(iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))),\n",
        "                      sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.005*255), per_channel=0.001)),\n",
        "                      sometimes(iaa.Dropout((0.001, 0.01), per_channel=0.5)),\n",
        "                      sometimes(iaa.Add((-10, 10), per_channel=0.5)),\n",
        "                      sometimes(iaa.Multiply((0.5, 1.5), per_channel=0.5)),\n",
        "                      sometimes(iaa.ElasticTransformation(alpha=(0.1, 0.2), sigma=0.05)),\n",
        "                      sometimes(iaa.PiecewiseAffine(scale=(0.001, 0.005)))\n",
        "                  ],\n",
        "                  random_order=True\n",
        "              )\n",
        "         ],\n",
        "        random_order=True\n",
        "    )\n",
        "    return seq.augment_images(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvJv8JjiaijD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import join\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "\n",
        "class TextImageGenerator:\n",
        "    def __init__(self,\n",
        "                 dirpath,\n",
        "                 img_w, img_h,\n",
        "                 batch_size,\n",
        "                 downsample_factor,\n",
        "                 letters,\n",
        "                 max_text_len,\n",
        "                 cname=\"\"):\n",
        "\n",
        "        self.CNAME = cname\n",
        "        #print(self.CNAME)\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.batch_size = batch_size\n",
        "        self.max_text_len = max_text_len\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.letters = letters\n",
        "\n",
        "        img_dirpath = join(dirpath, 'img')\n",
        "        ann_dirpath = join(dirpath, 'ann')\n",
        "        self.samples = []\n",
        "        for filename in os.listdir(img_dirpath):\n",
        "            name, ext = os.path.splitext(filename)\n",
        "            if ext == '.png':\n",
        "                img_filepath = join(img_dirpath, filename)\n",
        "                json_filepath = join(ann_dirpath, name + '.json')\n",
        "                description = json.load(open(json_filepath, 'r'))['description']\n",
        "                if TextImageGenerator.is_valid_str(self, description):\n",
        "                    self.samples.append([img_filepath, description])\n",
        "\n",
        "        self.n = len(self.samples)\n",
        "        self.indexes = list(range(self.n))\n",
        "        self.cur_index = 0\n",
        "        self.count_ep = 0\n",
        "        self.letters_max = len(letters)+1\n",
        "\n",
        "    def labels_to_text(self, labels):\n",
        "        data = ''.join(list(map(lambda x: \"\" if x==self.letters_max else self.letters[int(x)], labels)))\n",
        "        return data\n",
        "\n",
        "    def text_to_labels(self, text):\n",
        "        data = list(map(lambda x: self.letters.index(x), text))\n",
        "        while len(data) < self.max_text_len:\n",
        "            data.append(self.letters_max)\n",
        "        return data\n",
        "\n",
        "    def is_valid_str(self, s):\n",
        "        for ch in s:\n",
        "            if not ch in self.letters:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def decode_batch(self, out):\n",
        "        # Most change\n",
        "        # For a real OCR application, this should be beam search with a dictionary\n",
        "        # and language model.  For this example, best path is sufficient.\n",
        "        ret = []\n",
        "        for j in range(out.shape[0]):\n",
        "            out_best = list(np.argmax(out[j, 2:], 1))\n",
        "            out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "            outstr = ''\n",
        "            for c in out_best:\n",
        "                if c < len(self.letters):\n",
        "                    outstr += self.letters[c]\n",
        "            ret.append(outstr)\n",
        "        return ret\n",
        "\n",
        "    def build_data(self, aug_count=0):\n",
        "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
        "        self.texts = []\n",
        "        for i, (img_filepath, text) in enumerate(self.samples):\n",
        "            img = cv2.imread(img_filepath)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # CLAHE\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "            img = clahe.apply(img)\n",
        "\n",
        "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "            img = img.astype(np.float32)\n",
        "            img -= np.amin(img)\n",
        "            img /= np.amax(img)\n",
        "            # width and height are backwards from typical Keras convention\n",
        "            # because width is the time dimension when it gets fed into the RNN\n",
        "            self.imgs[i, :, :] = img\n",
        "            self.texts.append(text)\n",
        "        while aug_count:\n",
        "            for i, (img_filepath, text) in enumerate(self.samples):\n",
        "                img = cv2.imread(img_filepath)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                imgs = aug([img])\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "                img = imgs[0]\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # CLAHE\n",
        "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "                img = clahe.apply(img)\n",
        "\n",
        "                img = cv2.resize(img, (self.img_w, self.img_h))\n",
        "                img = img.astype(np.float32)\n",
        "                img -= np.amin(img)\n",
        "                img /= np.amax(img)\n",
        "                # width and height are backwards from typical Keras convention\n",
        "                # because width is the time dimension when it gets fed into the RNN\n",
        "                self.imgs[i, :, :] = img\n",
        "                self.texts.append(text)\n",
        "            aug_count -= 1\n",
        "\n",
        "\n",
        "    def get_output_size(self):\n",
        "        return len(self.letters) + 1\n",
        "\n",
        "    def normalize(self, img):\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        img = cv2.resize(img, (self.IMG_W, self.IMG_H))\n",
        "\n",
        "        # CLAHE\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        img = clahe.apply(img)\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "        img -= np.amin(img)\n",
        "        img /= np.amax(img)\n",
        "        img = [[[h] for h in w] for w in img.T]\n",
        "\n",
        "        x = np.zeros((self.IMG_W, self.IMG_H, 1))\n",
        "        x[:, :, :] = img\n",
        "        return x\n",
        "\n",
        "    def next_sample(self, is_random=1):\n",
        "        self.cur_index += 1\n",
        "        if self.cur_index >= self.n:\n",
        "            self.count_ep += 1\n",
        "            self.cur_index = 0\n",
        "            if is_random:\n",
        "                random.shuffle(self.indexes)\n",
        "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
        "\n",
        "    def next_batch(self, is_random=1, input_name=None, output_name=\"ctc\"):\n",
        "        if not input_name:\n",
        "            input_name = 'the_input_{}'.format(self.CNAME)\n",
        "        while True:\n",
        "            # width and height are backwards from typical Keras convention\n",
        "            # because width is the time dimension when it gets fed into the RNN\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
        "            else:\n",
        "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
        "\n",
        "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
        "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
        "            label_length = np.zeros((self.batch_size, 1))\n",
        "            source_str = []\n",
        "\n",
        "            for i in range(self.batch_size):\n",
        "                img, text = self.next_sample(is_random)\n",
        "                img = img.T\n",
        "                if K.image_data_format() == 'channels_first':\n",
        "                    img = np.expand_dims(img, 0)\n",
        "                else:\n",
        "                    img = np.expand_dims(img, -1)\n",
        "                X_data[i] = img\n",
        "                Y_data[i] = self.text_to_labels(text)\n",
        "                source_str.append(text)\n",
        "                label_length[i] = len(text)\n",
        "\n",
        "            inputs = {\n",
        "                '{}'.format(input_name): X_data,\n",
        "                'the_labels_{}'.format(self.CNAME): Y_data,\n",
        "                'input_length_{}'.format(self.CNAME): input_length,\n",
        "                'label_length_{}'.format(self.CNAME): label_length,\n",
        "                #'source_str': source_str\n",
        "            }\n",
        "            outputs = {'{}'.format(output_name): np.zeros([self.batch_size])}\n",
        "            yield (inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0IIE_deQC49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.core.protobuf import saver_pb2\n",
        "from tensorflow.python.training import saver as saver_lib\n",
        "from keras import backend as K\n",
        "\n",
        "def convert_keras_to_freeze_pb(model, frozen_model_path):\n",
        "        out_names = \",\".join([layer.name.split(\":\")[0]  for layer in model.outputs])\n",
        "        inp_names = \",\".join([layer.name.split(\":\")[0]  for layer in model.inputs])\n",
        "        print(\"OUTPUT: {}\".format(out_names))\n",
        "        print(\"INPUT: {}\".format(inp_names))\n",
        "        model.summary()\n",
        "        K.set_learning_phase(0)\n",
        "        sess = K.get_session()\n",
        "        saver = saver_lib.Saver(write_version=saver_pb2.SaverDef.V2)\n",
        "        checkpoint_path = saver.save(sess, '/content/drive/My Drive/LicensePlates/NEW/checkpoints/saved_ckpt', global_step=0, latest_filename='checkpoint_state')\n",
        "        graph_io.write_graph(sess.graph, '.', '/content/drive/My Drive/LicensePlates/NEW/checkpoints/tmp.pb')\n",
        "        freeze_graph.freeze_graph('/content/drive/My Drive/LicensePlates/NEW/checkpoints/tmp.pb', '',\n",
        "                                False, checkpoint_path, out_names,\n",
        "                                \"/content/drive/My Drive/LicensePlates/NEW/checkpoints/save/restore_all\",\n",
        "                                \"/content/drive/My Drive/LicensePlates/NEW/checkpoints/save/Const:0\",\n",
        "                                frozen_model_path,\n",
        "                                False, \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZuXgG-2XOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation\n",
        "from keras.layers import Reshape, Lambda\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing import image\n",
        "import keras.callbacks\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers import CuDNNGRU as GRUgpu\n",
        "from keras.layers.recurrent import GRU as GRUcpu\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "class OCR(TextImageGenerator):\n",
        "    @classmethod\n",
        "    def get_classname(cls):\n",
        "        return cls.__name__\n",
        "\n",
        "    def __init__(self):\n",
        "        # Input parameters\n",
        "        self.IMG_H = 64\n",
        "        self.IMG_W = 128\n",
        "        self.IMG_C = 1\n",
        "\n",
        "        # Train parameters\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.EPOCHS = 1\n",
        "\n",
        "        # Network parameters\n",
        "        self.CONV_FILTERS = 16\n",
        "        self.KERNEL_SIZE = (3, 3)\n",
        "        self.POOL_SIZE = 2\n",
        "        self.TIME_DENSE_SIZE = 32\n",
        "        self.RNN_SIZE = 512\n",
        "        self.ACTIVATION = 'relu'\n",
        "        self.DOWNSAMPLE_FACROT = self.POOL_SIZE * self.POOL_SIZE\n",
        "\n",
        "        self.GRU = GRUcpu\n",
        "\n",
        "        self.INPUT_NODE = \"the_input_{}:0\".format(type(self).__name__)\n",
        "        self.OUTPUT_NODE = \"softmax_{}/truediv:0\".format(type(self).__name__)\n",
        "\n",
        "    def get_counter(self, dirpath, verbose=1):\n",
        "        dirname = os.path.basename(dirpath)\n",
        "        ann_dirpath = join(dirpath, 'ann')\n",
        "        letters = ''\n",
        "        lens = []\n",
        "        for filename in os.listdir(ann_dirpath):\n",
        "            json_filepath = join(ann_dirpath, filename)\n",
        "            description = json.load(open(json_filepath, 'r'))['description']\n",
        "            lens.append(len(description))\n",
        "            letters += description\n",
        "        max_plate_length = max(Counter(lens).keys())\n",
        "        if verbose:\n",
        "            print('Max plate length in \"%s\":' % dirname, max_plate_length)\n",
        "        return Counter(letters), max_plate_length\n",
        "\n",
        "    def get_alphabet(self, train_path, test_path, val_path, verbose=1):\n",
        "        c_val, max_plate_length_val     = self.get_counter(val_path)\n",
        "        c_train, max_plate_length_train = self.get_counter(train_path)\n",
        "        c_test, max_plate_length_test   = self.get_counter(test_path)\n",
        "\n",
        "        letters_train = set(c_train.keys())\n",
        "        letters_val = set(c_val.keys())\n",
        "        letters_test = set(c_test.keys())\n",
        "        if verbose:\n",
        "            print(\"Letters train \", letters_train)\n",
        "            print(\"Letters val \", letters_val)\n",
        "            print(\"Letters test \", letters_test)\n",
        "\n",
        "        if max_plate_length_val == max_plate_length_train:\n",
        "            if verbose:\n",
        "                print('Max plate length in train, test and val do match')\n",
        "        else:\n",
        "            raise Exception('Max plate length in train, test and val do not match')\n",
        "\n",
        "        if letters_train == letters_val:\n",
        "            if verbose:\n",
        "                print('Letters in train, val and test do match')\n",
        "        else:\n",
        "            raise Exception('Letters in train, val and test do not match')\n",
        "\n",
        "        self.letters = sorted(list(letters_train))\n",
        "        self.max_text_len = max_plate_length_train\n",
        "        if verbose:\n",
        "            print('Letters:', ' '.join(self.letters))\n",
        "        return self.letters, self.max_text_len\n",
        "\n",
        "    def explainTextGenerator(self, train_dir, letters, max_plate_length, verbose=1):\n",
        "        tiger = TextImageGenerator(train_dir, self.IMG_W, self.IMG_H, 1, self.POOL_SIZE * self.POOL_SIZE, letters, max_plate_length, cname=type(self).__name__)\n",
        "        tiger.build_data()\n",
        "\n",
        "        for inp, out in tiger.next_batch():\n",
        "            print('Text generator output (data which will be fed into the neutral network):')\n",
        "            print('1) the_input (image)')\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                img = inp['the_input_{}'.format(type(self).__name__)][0, 0, :, :]\n",
        "            else:\n",
        "                img = inp['the_input_{}'.format(type(self).__name__)][0, :, :, 0]\n",
        "\n",
        "            #import matplotlib.pyplot as plt\n",
        "            #plt.imshow(img.T, cmap='gray')\n",
        "            #plt.show()\n",
        "            print('2) the_labels (plate number): %s is encoded as %s' %\n",
        "                  (tiger.labels_to_text(inp['the_labels_{}'.format(type(self).__name__)][0]), list(map(int, inp['the_labels_{}'.format(type(self).__name__)][0]))))\n",
        "            print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' %\n",
        "                  (inp['input_length_{}'.format(type(self).__name__)][0], tiger.img_w))\n",
        "            print('4) label_length (length of plate number): %d' % inp['label_length_{}'.format(type(self).__name__)][0])\n",
        "            break\n",
        "\n",
        "    def ctc_lambda_func(self, args):\n",
        "        y_pred, labels, input_length, label_length = args\n",
        "        # the 2 is critical here since the first couple outputs of the RNN\n",
        "        # tend to be garbage:\n",
        "        y_pred = y_pred[:, 2:, :]\n",
        "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "    def save(self, path, verbose=1):\n",
        "        if self.MODEL:\n",
        "            self.MODEL.save(path)\n",
        "            if verbose:\n",
        "                print(\"SAVED TO {}\".format(path))\n",
        "\n",
        "    def test(self, verbose=1, random_state=1):\n",
        "        if verbose:\n",
        "            print(\"\\nRUN TEST\")\n",
        "            start_time = time.time()\n",
        "        net_inp = self.MODEL.get_layer(name='{}'.format(self.MODEL.layers[0].name)).input\n",
        "        net_out = self.MODEL.get_layer(name='{}'.format(self.MODEL.layers[-1].name)).output\n",
        "\n",
        "        err_c = 0\n",
        "        succ_c = 0\n",
        "        for inp_value, _ in self.tiger_test.next_batch(random_state, input_name=self.MODEL.layers[0].name, output_name=self.MODEL.layers[-1].name):\n",
        "            bs = inp_value['the_input_{}'.format(type(self).__name__)].shape[0]\n",
        "            X_data = inp_value['the_input_{}'.format(type(self).__name__)]\n",
        "            net_out_value = self.SESS.run(net_out, feed_dict={net_inp:X_data})\n",
        "            pred_texts = self.tiger_test.decode_batch(net_out_value)\n",
        "            labels = inp_value['the_labels_{}'.format(type(self).__name__)]\n",
        "            texts = []\n",
        "            for label in labels:\n",
        "                text = self.tiger_test.labels_to_text(label)\n",
        "                texts.append(text)\n",
        "\n",
        "            for i in range(bs):\n",
        "                if (pred_texts[i] != texts[i]):\n",
        "                    if verbose:\n",
        "                        print('\\nPredicted: \\t\\t %s\\nTrue: \\t\\t\\t %s' % (pred_texts[i], texts[i]))\n",
        "                    err_c += 1\n",
        "                else:\n",
        "                    succ_c += 1\n",
        "            break\n",
        "        if verbose:\n",
        "            print(\"Test processing time: {} seconds\".format(time.time() - start_time))\n",
        "        print(\"acc: {}\".format(succ_c/(err_c+succ_c)))\n",
        "\n",
        "    def predict(self, imgs, *argv):\n",
        "        Xs = []\n",
        "        for img in imgs:\n",
        "            x = self.normalize(img)\n",
        "            Xs.append(x)\n",
        "        pred_texts = []\n",
        "        if bool(Xs):\n",
        "            net_out_value = self.MODEL.predict(np.array(Xs))\n",
        "            #print(net_out_value)\n",
        "            pred_texts = self.decode_batch(net_out_value)\n",
        "        return pred_texts\n",
        "\n",
        "    def load(self, path_to_model, mode=\"cpu\", verbose = 0):\n",
        "        if path_to_model ==\"latest\":\n",
        "            model_info = download_latest_model(\"TextDetector\", self.get_classname(), mode=mode)\n",
        "            path_to_model = model_info[\"path\"]\n",
        "\n",
        "\n",
        "        self.MODEL = load_model(path_to_model, compile=False)\n",
        "\n",
        "        net_inp = self.MODEL.get_layer(name='{}'.format(self.MODEL.layers[0].name)).input\n",
        "        net_out = self.MODEL.get_layer(name='{}'.format(self.MODEL.layers[-1].name)).output\n",
        "\n",
        "        self.MODEL = Model(input=net_inp, output=net_out)\n",
        "\n",
        "        if verbose:\n",
        "            self.MODEL.summary()\n",
        "\n",
        "        # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "        #sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "        #self.MODEL.compile(loss={'{}'.format(model.layers[-1].name): lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
        "\n",
        "        return self.MODEL\n",
        "\n",
        "    def prepare(self, path_to_dataset, aug_count=0, verbose=1):\n",
        "        self.SESS = tf.Session()\n",
        "        K.set_session(self.SESS)\n",
        "\n",
        "        train_path = os.path.join(path_to_dataset, \"train\")\n",
        "        test_path  = os.path.join(path_to_dataset, \"test\")\n",
        "        val_path   = os.path.join(path_to_dataset, \"val\")\n",
        "\n",
        "        if verbose:\n",
        "            print(\"GET ALPHABET\")\n",
        "        self.letters, max_plate_length = self.get_alphabet(train_path, test_path, val_path, verbose=verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nEXPLAIN DATA TRANSFORMATIONS\")\n",
        "            self.explainTextGenerator(train_path, self.letters, max_plate_length)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"START BUILD DATA\")\n",
        "        self.tiger_train = TextImageGenerator(train_path, self.IMG_W, self.IMG_H, self.BATCH_SIZE, self.DOWNSAMPLE_FACROT, self.letters, max_plate_length, cname=type(self).__name__)\n",
        "        self.tiger_train.build_data(aug_count=aug_count)\n",
        "        self.tiger_val = TextImageGenerator(val_path,  self.IMG_W, self.IMG_H, self.BATCH_SIZE, self.DOWNSAMPLE_FACROT, self.letters, max_plate_length, cname=type(self).__name__)\n",
        "        self.tiger_val.build_data()\n",
        "\n",
        "        self.tiger_test = TextImageGenerator(test_path, self.IMG_W, self.IMG_H, len(os.listdir(os.path.join(test_path, \"img\"))), self.DOWNSAMPLE_FACROT, self.letters, max_plate_length, cname=type(self).__name__)\n",
        "        self.tiger_test.build_data()\n",
        "        if verbose:\n",
        "            print(\"DATA PREPARED\")\n",
        "\n",
        "    def train(self, mode=\"gpu\", is_random=1, model_path=\"/content/drive/My Drive/LicensePlates/NEW/models/second.h5\", load=False, verbose=1):\n",
        "        if mode == \"gpu\":\n",
        "            self.GRU = GRUgpu\n",
        "        if mode == \"cpu\":\n",
        "            self.GRU = GRUcpu\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nSTART TRAINING\")\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            input_shape = (1, self.IMG_W, self.IMG_H)\n",
        "        else:\n",
        "            input_shape = (self.IMG_W, self.IMG_H, 1)\n",
        "\n",
        "        input_data = Input(name='the_input_{}'.format(type(self).__name__), shape=input_shape, dtype='float32')\n",
        "        inner = Conv2D(self.CONV_FILTERS, self.KERNEL_SIZE, padding='same',\n",
        "                       activation=self.ACTIVATION, kernel_initializer='he_normal',\n",
        "                       name='conv1')(input_data)\n",
        "        inner = MaxPooling2D(pool_size=(self.POOL_SIZE , self.POOL_SIZE ), name='max1')(inner)\n",
        "        inner = Conv2D(self.CONV_FILTERS, self.KERNEL_SIZE, padding='same',\n",
        "                       activation=self.ACTIVATION, kernel_initializer='he_normal',\n",
        "                       name='conv2')(inner)\n",
        "        inner = MaxPooling2D(pool_size=(self.POOL_SIZE , self.POOL_SIZE ), name='max2')(inner)\n",
        "\n",
        "        conv_to_rnn_dims = (self.IMG_W // (self.POOL_SIZE  * self.POOL_SIZE), (self.IMG_H // (self.POOL_SIZE * self.POOL_SIZE)) * self.CONV_FILTERS)\n",
        "        inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "\n",
        "        # cuts down input size going into RNN:\n",
        "        inner = Dense(self.TIME_DENSE_SIZE, activation=self.ACTIVATION, name='dense1')(inner)\n",
        "\n",
        "        # Two layers of bidirecitonal GRUs\n",
        "        # GRU seems to work as well, if not better than LSTM:\n",
        "        gru_1 = self.GRU(self.RNN_SIZE, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
        "        gru_1b = self.GRU(self.RNN_SIZE, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "        gru1_merged = add([gru_1, gru_1b])\n",
        "        gru_2 = self.GRU(self.RNN_SIZE, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "        gru_2b = self.GRU(self.RNN_SIZE, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "\n",
        "        # transforms RNN output to character activations:\n",
        "        inner = Dense(self.tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
        "                      name='dense2')(concatenate([gru_2, gru_2b]))\n",
        "        y_pred = Activation('softmax', name='softmax_{}'.format(type(self).__name__))(inner)\n",
        "        Model(inputs=input_data, outputs=y_pred).summary()\n",
        "\n",
        "        labels = Input(name='the_labels_{}'.format(type(self).__name__), shape=[self.tiger_train.max_text_len], dtype='float32')\n",
        "        input_length = Input(name='input_length_{}'.format(type(self).__name__), shape=[1], dtype='int64')\n",
        "        label_length = Input(name='label_length_{}'.format(type(self).__name__), shape=[1], dtype='int64')\n",
        "        # Keras doesn't currently support loss funcs with extra parameters\n",
        "        # so CTC loss is implemented in a lambda layer\n",
        "        loss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "        # clipnorm seems to speeds up convergence\n",
        "        sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "\n",
        "        if load:\n",
        "            model = load_model(model_path, compile=False)\n",
        "        else:\n",
        "            model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "        # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "        model.compile(loss={'{}'.format(model.layers[-1].name): lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
        "\n",
        "        # captures output of softmax so we can decode the output during visualization\n",
        "        test_func = K.function([input_data], [y_pred])\n",
        "\n",
        "        model.fit_generator(generator=self.tiger_train.next_batch(is_random, input_name=model.layers[0].name, output_name=model.layers[-1].name),\n",
        "                            steps_per_epoch=self.tiger_train.n,\n",
        "                            epochs=self.EPOCHS,\n",
        "                            validation_data=self.tiger_val.next_batch(is_random, input_name=model.layers[0].name, output_name=model.layers[-1].name),\n",
        "                            validation_steps=self.tiger_val.n)\n",
        "\n",
        "        print(\"Models layers: \", [i.name for i in model.layers])\n",
        "        # net_inp = model.get_layer(name='{}'.format(model.layers[0].name)).input\n",
        "        # net_out = model.get_layer(name='{}'.format(model.layers[-1].name)).output\n",
        "        self.MODEL = Model(inputs=input_data, outputs=y_pred)\n",
        "        # self.MODEL = model\n",
        "        return self.MODEL\n",
        "\n",
        "    def load_frozen(self, FROZEN_MODEL_PATH, mode=\"cpu\"):\n",
        "        graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(FROZEN_MODEL_PATH, \"rb\") as f:\n",
        "            graph_def.ParseFromString(f.read())\n",
        "\n",
        "        #print([x.name for x in graph_def.node])\n",
        "        graph = tf.Graph()\n",
        "        with graph.as_default():\n",
        "            self.net_inp, self.net_out = tf.import_graph_def(\n",
        "                graph_def, return_elements = [self.INPUT_NODE, self.OUTPUT_NODE]\n",
        "            )\n",
        "\n",
        "        sess_config = tf.ConfigProto()\n",
        "        sess_config.gpu_options.allow_growth = True\n",
        "        self.sess = tf.Session(graph=graph, config=sess_config)\n",
        "\n",
        "    def frozen_predict(self, imgs):\n",
        "        Xs = []\n",
        "        for img in imgs:\n",
        "            x = self.normalize(img)\n",
        "            Xs.append(x)\n",
        "        pred_texts = []\n",
        "        if bool(Xs):\n",
        "            net_out_value = self.sess.run([self.net_out], feed_dict={self.net_inp: np.array(Xs)})\n",
        "            #print(net_out_value)\n",
        "            pred_texts = self.decode_batch(net_out_value[0])\n",
        "        return pred_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV1DCf72QKuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# change this property\n",
        "# NOMEROFF_NET_DIR = os.path.abspath('/content/drive/My Drive/LicensePlates/NEW/')\n",
        "NOMEROFF_NET_DIR = os.path.abspath('/content/autoriaNumberplateOcrRu-2019-08-30/')\n",
        "\n",
        "DATASET_NAME = \"ru\"\n",
        "VERSION = \"1\"\n",
        "MODE = \"gpu\"\n",
        "# PATH_TO_DATASET = os.path.join(NOMEROFF_NET_DIR, \"data/autoriaNumberplateOcrRu-2019-08-30/\")\n",
        "# PATH_TO_DATASET = os.path.join(NOMEROFF_NET_DIR, \"data_short/ocr-2020/\")\n",
        "PATH_TO_DATASET = os.path.join(NOMEROFF_NET_DIR)\n",
        "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \"models/\", 'anpr_ocr_{}_{}-{}.h5'.format(DATASET_NAME, VERSION, MODE))\n",
        "\n",
        "FROZEN_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \"models/\", 'anpr_ocr_{}_{}-{}.pb'.format(DATASET_NAME, VERSION, MODE))\n",
        "\n",
        "sys.path.append(NOMEROFF_NET_DIR)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdYFMNC5R7eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ru_train(OCR):\n",
        "    def __init__(self):\n",
        "        OCR.__init__(self)\n",
        "        # only for usage model\n",
        "        # in train generate automaticly\n",
        "        # self.letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"E\", \"H\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\"]\n",
        "        \n",
        "        self.EPOCHS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NswJk08DSK5P",
        "colab_type": "code",
        "outputId": "23e95228-e607-42de-d99a-d90ae35a064b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "ocrTextDetector = ru_train()\n",
        "model = ocrTextDetector.prepare(PATH_TO_DATASET, aug_count=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GET ALPHABET\n",
            "Max plate length in \"val\": 9\n",
            "Max plate length in \"train\": 9\n",
            "Max plate length in \"test\": 9\n",
            "Letters train  {'Y', 'H', '2', '4', '5', 'K', '6', '9', 'O', 'M', '1', 'P', '7', '8', '0', 'A', 'E', 'X', 'C', '3', 'B', 'T'}\n",
            "Letters val  {'Y', 'H', '2', '4', '5', 'K', '6', '9', 'O', 'M', '1', 'P', '7', '8', '0', 'A', 'X', 'E', 'C', '3', 'B', 'T'}\n",
            "Letters test  {'Y', 'H', '2', '4', '5', 'K', '6', '9', 'O', 'M', '1', 'P', '7', '8', '0', 'A', 'X', 'E', 'C', '3', 'B', 'T'}\n",
            "Max plate length in train, test and val do match\n",
            "Letters in train, val and test do match\n",
            "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n",
            "\n",
            "EXPLAIN DATA TRANSFORMATIONS\n",
            "Text generator output (data which will be fed into the neutral network):\n",
            "1) the_input (image)\n",
            "2) the_labels (plate number): T763PP35 is encoded as [19, 7, 6, 3, 18, 18, 3, 5, 23]\n",
            "3) input_length (width of image that is fed to the loss function): 30 == 128 / 4 - 2\n",
            "4) label_length (length of plate number): 8\n",
            "START BUILD DATA\n",
            "DATA PREPARED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04DrrqtrSOTJ",
        "colab_type": "code",
        "outputId": "d168b1d6-bb1b-42bf-c95a-2d25164a670c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "model = ocrTextDetector.train(mode=MODE, is_random=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "START TRAINING\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input_ru_train (InputLayer) (None, 128, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input_ru_train[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (CuDNNGRU)                 (None, 32, 512)      838656      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (CuDNNGRU)               (None, 32, 512)      838656      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (CuDNNGRU)                 (None, 32, 512)      1575936     add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (CuDNNGRU)               (None, 32, 512)      1575936     add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 32, 23)       23575       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax_ru_train (Activation)   (None, 32, 23)       0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,863,463\n",
            "Trainable params: 4,863,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/3\n",
            "9716/9716 [==============================] - 544s 56ms/step - loss: 2.7716 - val_loss: 0.6924\n",
            "Epoch 2/3\n",
            "9716/9716 [==============================] - 543s 56ms/step - loss: 0.2671 - val_loss: 0.7441\n",
            "Epoch 3/3\n",
            "9716/9716 [==============================] - 546s 56ms/step - loss: 0.2096 - val_loss: 0.7405\n",
            "Models layers:  ['the_input_ru_train', 'conv1', 'max1', 'conv2', 'max2', 'reshape', 'dense1', 'gru1', 'gru1_b', 'add_1', 'gru2', 'gru2_b', 'concatenate_1', 'dense2', 'softmax_ru_train', 'the_labels_ru_train', 'input_length_ru_train', 'label_length_ru_train', 'ctc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOr7CEwuyDOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESULT_MODEL_PATH = '/content/drive/My Drive/LicensePlates/NEW/models/96percent.h5'\n",
        "ocrTextDetector.save(RESULT_MODEL_PATH, verbose=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Cq7bZjxWCk",
        "colab_type": "code",
        "outputId": "33a9e89e-148a-4d93-a517-04b4c5d76358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ocrTextDetector.test(verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RUN TEST\n",
            "\n",
            "Predicted: \t\t K707KP580\n",
            "True: \t\t\t K707KP58\n",
            "\n",
            "Predicted: \t\t K733KB78\n",
            "True: \t\t\t X733KB78\n",
            "\n",
            "Predicted: \t\t T135OA3\n",
            "True: \t\t\t T135OA33\n",
            "\n",
            "Predicted: \t\t M056HX29\n",
            "True: \t\t\t H056HX29\n",
            "\n",
            "Predicted: \t\t A302TT16525\n",
            "True: \t\t\t A302TT152\n",
            "\n",
            "Predicted: \t\t H120HH32\n",
            "True: \t\t\t H120HH39\n",
            "\n",
            "Predicted: \t\t X518XX652\n",
            "True: \t\t\t X518XX61\n",
            "\n",
            "Predicted: \t\t M882MM11\n",
            "True: \t\t\t M882MM12\n",
            "\n",
            "Predicted: \t\t B639MY114\n",
            "True: \t\t\t B639MY116\n",
            "\n",
            "Predicted: \t\t H008YH64\n",
            "True: \t\t\t H008HH64\n",
            "\n",
            "Predicted: \t\t T639AP197\n",
            "True: \t\t\t T689AP197\n",
            "\n",
            "Predicted: \t\t T522TT33\n",
            "True: \t\t\t T522TT39\n",
            "\n",
            "Predicted: \t\t X193BH196\n",
            "True: \t\t\t X193BH197\n",
            "\n",
            "Predicted: \t\t E2B2PO46\n",
            "True: \t\t\t E282PO46\n",
            "\n",
            "Predicted: \t\t K770KY335\n",
            "True: \t\t\t K770KY33\n",
            "\n",
            "Predicted: \t\t E555BY192\n",
            "True: \t\t\t E555BY102\n",
            "\n",
            "Predicted: \t\t H209CY228\n",
            "True: \t\t\t H209CY22\n",
            "\n",
            "Predicted: \t\t B648AB29\n",
            "True: \t\t\t H648AB29\n",
            "\n",
            "Predicted: \t\t Y013YY74\n",
            "True: \t\t\t Y013YY26\n",
            "Test processing time: 0.5713357925415039 seconds\n",
            "acc: 0.9613034623217923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJmM3py6N111",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload model\n",
        "RESULT_MODEL_PATH = '/content/drive/My Drive/LicensePlates/NEW/models/96percent.h5'\n",
        "model =ocrTextDetector.load(RESULT_MODEL_PATH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgJJXNqtOtBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "def hand_image_prep(filename:str):\n",
        "    img = cv2.imread(filename, 0)\n",
        "    print(img.shape)\n",
        "    # img = img[np.newaxis, ...]\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_GBR2GRAY)\n",
        "\n",
        "    # CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    img = clahe.apply(img)\n",
        "\n",
        "    img = cv2.resize(img, (64, 128))\n",
        "    img = img.astype(np.float32)\n",
        "    img -= np.amin(img)\n",
        "    img /= np.amax(img)\n",
        "    # width and height are backwards from typical Keras convention\n",
        "    # because width is the time dimension when it gets fed into the RNN\n",
        "    # img[1, :, :] = img\n",
        "    # img = img[np.newaxis, ...]\n",
        "    print(img.shape)\n",
        "\n",
        "    return img\n",
        "img = hand_image_prep('/content/drive/My Drive/LicensePlates/plates_examples/car_plate_rus_5_cut.jpg')\n",
        "a = ocrTextDetector.predict([img])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B3NMJPUkClG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/LicensePlates/plates_examples/car_plate_rus_4_cut.jpg')\n",
        "\n",
        "a = ocrTextDetector.predict([img])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lygb6dHxTDuU",
        "colab_type": "code",
        "outputId": "cbdb9d43-090b-49f2-a025-9e789756d783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['P719XK77']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvgzvnXuyb2F",
        "colab_type": "code",
        "outputId": "591dfe39-6b6a-4c56-b2f8-6500e478639c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "# Converting h5(keras) to pb(tf)\n",
        "import keras\n",
        "keras.backend.clear_session()\n",
        "model = ocrTextDetector.load(RESULT_MODEL_PATH)\n",
        "# model = ocrTextDetector.load('/content/drive/My Drive/LicensePlates/NEW/models/ru_my.h5')\n",
        "convert_keras_to_freeze_pb(model, '/content/drive/My Drive/LicensePlates/NEW/models/96_percent.pb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUT: softmax_ru_train/truediv\n",
            "INPUT: the_input_ru_train\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input_ru_train (InputLayer) (None, 128, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input_ru_train[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (CuDNNGRU)                 (None, 32, 512)      838656      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (CuDNNGRU)               (None, 32, 512)      838656      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (CuDNNGRU)                 (None, 32, 512)      1575936     add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (CuDNNGRU)               (None, 32, 512)      1575936     add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 32, 23)       23575       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax_ru_train (Activation)   (None, 32, 23)       0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,863,463\n",
            "Trainable params: 4,863,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/LicensePlates/NEW/checkpoints/saved_ckpt-0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 20 variables.\n",
            "INFO:tensorflow:Converted 20 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMsgDyyHy1zz",
        "colab_type": "code",
        "outputId": "1805b99a-6fac-4ad5-d09d-d2b9e9820254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from math import exp \n",
        "exp(16.11)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9919370.3057168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgFRaAVj7XzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}